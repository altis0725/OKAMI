#!/usr/bin/env python
"""
ã‚°ãƒ©ãƒ•ãƒ¡ãƒ¢ãƒªæ©Ÿèƒ½ã®ãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ¡ãƒ¢ãƒªã‚’ã‚°ãƒ©ãƒ•æ§‹é€ ã§ç®¡ç†ã™ã‚‹æ©Ÿèƒ½ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import os
import sys
from pathlib import Path
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.graph_memory_manager import GraphMemoryManager
from core.knowledge_graph_integration import KnowledgeGraphIntegration
from core.memory_manager import MemoryManager


def demonstrate_graph_memory():
    """ã‚°ãƒ©ãƒ•ãƒ¡ãƒ¢ãƒªã®åŸºæœ¬æ©Ÿèƒ½ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    print("=" * 60)
    print("ğŸ§  OKAMI Graph Memory System Demo")
    print("=" * 60)
    print()
    
    # GraphMemoryManagerã®åˆæœŸåŒ–
    print("ğŸ“Š Initializing Graph Memory Manager...")
    graph_memory = GraphMemoryManager(storage_path="storage/demo_graph_memory")
    
    # åˆæœŸçŠ¶æ…‹ã‚’è¡¨ç¤º
    stats = graph_memory.get_graph_statistics()
    print(f"Initial state: {stats['total_nodes']} nodes, {stats['total_edges']} edges")
    print()
    
    # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã‚’è¨˜éŒ²
    print("ğŸ“ Recording task executions...")
    tasks = [
        {
            "task_id": "research_001",
            "agent_name": "research_agent",
            "task_description": "Research the latest AI trends in 2025",
            "result": "Found 5 major trends: Multi-modal AI, Agentic AI, Smaller models, AI safety, and Edge AI",
            "success": True
        },
        {
            "task_id": "analysis_001",
            "agent_name": "analysis_agent",
            "task_description": "Analyze the impact of multi-modal AI on business",
            "result": "Multi-modal AI is transforming customer service, content creation, and data analysis",
            "success": True
        },
        {
            "task_id": "writer_001",
            "agent_name": "writer_agent",
            "task_description": "Write a summary report on AI trends",
            "result": "Report completed with executive summary and detailed analysis",
            "success": True
        }
    ]
    
    for task in tasks:
        graph_memory.record_task_execution(**task)
        print(f"  âœ… Recorded: {task['task_description'][:50]}...")
    
    print()
    
    # ã‚°ãƒ©ãƒ•ã®çŠ¶æ…‹ã‚’è¡¨ç¤º
    stats = graph_memory.get_graph_statistics()
    print(f"After recording: {stats['total_nodes']} nodes, {stats['total_edges']} edges")
    print(f"Node types: {stats['node_types']}")
    print(f"Relation types: {stats['relation_types']}")
    print()
    
    # ãƒ¡ãƒ¢ãƒªæ¤œç´¢
    print("ğŸ” Searching memories...")
    search_query = "AI"
    results = graph_memory.search_memories(query=search_query, limit=5)
    print(f"Search for '{search_query}' found {len(results)} results:")
    for result in results[:3]:
        print(f"  - {result['node_type']}: {result['content'][:60]}...")
    print()
    
    # é–¢é€£ãƒ¡ãƒ¢ãƒªã®æ¢ç´¢
    print("ğŸ•¸ï¸ Finding related memories...")
    if results:
        node_id = results[0]['id']
        related = graph_memory.find_related_memories(
            node_id=node_id,
            max_depth=2,
            limit=5
        )
        print(f"Found {len(related)} memories related to '{node_id}':")
        for rel in related[:3]:
            print(f"  - {rel['node_type']} ({rel['distance']} hops): {rel['content'][:50]}...")
    print()
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å±¥æ­´
    print("ğŸ“ˆ Agent performance history...")
    for agent_name in ["research_agent", "analysis_agent", "writer_agent"]:
        history = graph_memory.get_agent_performance_history(agent_name)
        if history.get('total_tasks', 0) > 0:
            print(f"  {agent_name}:")
            print(f"    - Total tasks: {history['total_tasks']}")
            print(f"    - Success rate: {history['success_rate']:.0%}")
    print()
    
    # çŸ¥è­˜ã‚®ãƒ£ãƒƒãƒ—ã®ç‰¹å®š
    print("ğŸ” Identifying knowledge gaps...")
    gaps = graph_memory.identify_knowledge_gaps()
    if gaps:
        print(f"Found {len(gaps)} knowledge gaps:")
        for gap in gaps[:3]:
            print(f"  - {gap['type']}: {gap['suggestion']}")
    else:
        print("  No significant knowledge gaps found")
    print()
    
    # ã‚°ãƒ©ãƒ•ã®ä¿å­˜
    print("ğŸ’¾ Saving graph to disk...")
    graph_memory.save_memory_graph()
    print("  Graph saved successfully")
    print()
    
    return graph_memory


def demonstrate_integration():
    """çŸ¥è­˜ã‚°ãƒ©ãƒ•çµ±åˆã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    print("=" * 60)
    print("ğŸ”— Knowledge-Graph Integration Demo")
    print("=" * 60)
    print()
    
    # çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    print("ğŸš€ Initializing integrated system...")
    memory_manager = MemoryManager(
        storage_path="storage/demo_memory",
        use_graph_memory=True
    )
    
    if not memory_manager.graph_memory:
        print("  âš ï¸ Graph memory not available")
        return
    
    print("  âœ… Memory Manager initialized with graph memory")
    print()
    
    # ã‚¿ã‚¹ã‚¯ã‚’ã‚°ãƒ©ãƒ•ã«è¨˜éŒ²
    print("ğŸ“Š Recording task in graph...")
    memory_manager.record_task_in_graph(
        task_id="demo_001",
        agent_name="demo_agent",
        task_description="Demonstrate integration features",
        result="Integration successful with all components working",
        success=True
    )
    print("  âœ… Task recorded in graph memory")
    print()
    
    # ã‚°ãƒ©ãƒ•ãƒ¡ãƒ¢ãƒªã‚’æ¤œç´¢
    print("ğŸ” Searching graph memory...")
    results = memory_manager.search_graph_memory(
        query="integration",
        limit=5
    )
    print(f"  Found {len(results)} results")
    for result in results:
        print(f"    - {result.get('node_type', 'unknown')}: {result.get('content', '')[:50]}...")
    print()
    
    # æ‹¡å¼µãƒ¡ãƒ¢ãƒªè¨­å®šã‚’å–å¾—
    print("âš™ï¸ Enhanced memory configuration:")
    config = memory_manager.get_enhanced_memory_config()
    if "graph_memory" in config:
        graph_config = config["graph_memory"]
        print(f"  - Enabled: {graph_config['enabled']}")
        print(f"  - Storage: {graph_config['storage_path']}")
        if 'statistics' in graph_config:
            stats = graph_config['statistics']
            print(f"  - Nodes: {stats.get('total_nodes', 0)}")
            print(f"  - Edges: {stats.get('total_edges', 0)}")
    print()


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("\nğŸš€ Starting OKAMI Graph Memory Demo\n")
    
    # åŸºæœ¬çš„ãªã‚°ãƒ©ãƒ•ãƒ¡ãƒ¢ãƒªã®ãƒ‡ãƒ¢
    graph_memory = demonstrate_graph_memory()
    
    # çµ±åˆæ©Ÿèƒ½ã®ãƒ‡ãƒ¢
    demonstrate_integration()
    
    print("=" * 60)
    print("âœ¨ Demo completed successfully!")
    print("=" * 60)
    print()
    
    # æœ€çµ‚çµ±è¨ˆ
    final_stats = graph_memory.get_graph_statistics()
    print("ğŸ“Š Final statistics:")
    print(f"  - Total nodes: {final_stats['total_nodes']}")
    print(f"  - Total edges: {final_stats['total_edges']}")
    print(f"  - Connected components: {final_stats['connected_components']}")
    print(f"  - Average degree: {final_stats['average_degree']:.2f}")
    print()
    
    print("ğŸ’¡ Graph memory enables:")
    print("  - Structured memory storage with relationships")
    print("  - Semantic search across memories")
    print("  - Performance tracking for agents")
    print("  - Knowledge gap identification")
    print("  - Context-aware task execution")
    print()


if __name__ == "__main__":
    main()