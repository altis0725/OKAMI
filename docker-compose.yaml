services:
  # Main OKAMI service
  okami:
    build: .
    container_name: okami-main
    ports:
      - "8000:8000"
    volumes:
      - ./:/app
      - ./storage:/app/storage
      - ./logs:/app/logs
      - ./knowledge:/app/knowledge
    environment:
      - PYTHONUNBUFFERED=1
      - CREWAI_STORAGE_DIR=/app/storage
      - CREWAI_DISABLE_TELEMETRY=true
      - OTEL_SDK_DISABLED=true
      - LOG_LEVEL=INFO
      - EMBEDDER_PROVIDER=ollama
      - EMBEDDER_MODEL=mxbai-embed-large
      - VECTOR_STORE_TYPE=chroma
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
      # ChromaDBをHTTPクライアントモードで使用（永続化はChromaDB側で管理）
      - CHROMA_PERSIST_DIRECTORY=
      - USE_QDRANT=false
      # CrewAI内部メモリ用のChroma設定
      - CHROMA_SERVER_HOST=chromadb
      - CHROMA_SERVER_HTTP_PORT=8000
      # CrewAI知識ベース用の設定
      - CREWAI__EMBEDDINGS__PROVIDER=ollama
      - CREWAI__EMBEDDINGS__MODEL=mxbai-embed-large
    env_file:
      - .env
    networks:
      - okami-network
    depends_on:
      - chromadb
      - ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Claude Code Quality Monitor service
  claude-monitor:
    build:
      context: .
      dockerfile: Dockerfile.monitor
    container_name: okami-quality-monitor
    volumes:
      - ./monitoring:/app/monitoring
      - ./logs:/app/logs
    environment:
      - OKAMI_API_URL=http://okami:8000
      - QUALITY_CHECK_INTERVAL=30
      - LOG_LEVEL=INFO
    env_file:
      - .env
    depends_on:
      okami:
        condition: service_healthy
    networks:
      - okami-network
    restart: unless-stopped

  # ChromaDB for vector storage（最新版対応設定）
  chromadb:
    image: chromadb/chroma:0.5.23  # CrewAIとの互換性確保のため0.5.23に固定
    container_name: okami-chromadb
    ports:
      - "8001:8000"
    volumes:
      - chroma-data:/chroma/chroma  # 将来の1.0.x系では /data に変更予定
    environment:
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=FALSE
      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=["*"]  # CORS設定追加
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      # 1.0.x系移行時に必要な設定（現在はコメントアウト）
      # - CHROMA_SERVER_AUTHN_CREDENTIALS_FILE=/chroma/credentials
      # - CHROMA_SERVER_AUTHN_PROVIDER=chromadb.auth.token_authn.TokenAuthenticationServerProvider
    networks:
      - okami-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Ollama for local embeddings（最新版対応）
  ollama:
    image: ollama/ollama:latest  # 最新版を使用（元の設定に戻す）
    container_name: okami-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
      - ./scripts/ollama-entrypoint.sh:/entrypoint.sh:ro
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*  # CORS設定（v0.5.0以降で必要）
      - OLLAMA_NUM_PARALLEL=1  # バッチ処理を無効化（エラー回避）
      - OLLAMA_MAX_LOADED_MODELS=1  # エンベディングモデル1つに制限
      - OLLAMA_KEEP_ALIVE=5m  # モデルをメモリに保持
      - OLLAMA_MODELS=/root/.ollama/models  # モデルパスを明示
      - OLLAMA_DEBUG=1  # デバッグログを有効化
      - OLLAMA_API_BASE_URL=http://0.0.0.0:11434  # 明示的なAPI設定
    networks:
      - okami-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]  # 軽量エンドポイントに変更
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s  # 起動時間を短縮
    entrypoint: ["/bin/bash", "/entrypoint.sh"]
    deploy:
      resources:
        limits:
          memory: 8G  # メモリ上限を設定
        reservations:
          memory: 4G  # 最小メモリを確保

volumes:
  chroma-data:
  ollama-data:

networks:
  okami-network:
    driver: bridge
